{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Xi Chen\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "# Borrowed from https://github.com/neocxi/pixelsnail-public and ported it to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import importlib \n",
    "from math import sqrt\n",
    "from functools import partial, lru_cache\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from vq_vae_2 import Model\n",
    "from pixel_snail import PixelSNAIL\n",
    "from scheduler import CycleScheduler\n",
    "\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqja1998\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gibeom/audio/emotional_annotations/wandb/run-20230207_063129-2bx3s1am</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/qja1998/audio-emotional_annotations/runs/2bx3s1am\" target=\"_blank\">stellar-oath-183</a></strong> to <a href=\"https://wandb.ai/qja1998/audio-emotional_annotations\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()\n",
    "wandb.run.name = 'PixelSNAIL'\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_split = 100\n",
    "class MelData(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = []\n",
    "        genre = ['classical', 'rock', 'electronic', 'pop', 'deam']\n",
    "        print(\"Load data...\")\n",
    "        for g in genre:\n",
    "            print(f'{g}:')\n",
    "            for i in tqdm(range(1, 2059)):\n",
    "                for j in range(num_split):\n",
    "                    tmp_path = f'{file_path}/{g}/{i}-{j}.csv'\n",
    "                    try:\n",
    "                        mel = pd.read_csv(tmp_path).iloc[:, :512]\n",
    "                        if mel.shape == (80, 512):\n",
    "                            self.data.append((mel, g, i, j))\n",
    "                    except FileNotFoundError:\n",
    "                        continue\n",
    "            print()\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mel, g, i, j = self.data[idx]\n",
    "        mel = torch.from_numpy(pd.get_dummies(mel).values)\n",
    "        mel = mel.type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        return (g, i, j), mel\n",
    "\n",
    "class EmotionalData(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tmp_data = self.data.iloc[idx]\n",
    "        genre, idx = tmp_data[0].split('_')\n",
    "        emo = tmp_data[1:]\n",
    "        return idx, genre, torch.FloatTensor(emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "classical:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd057d4840e4a2ca5ad2aba8a5f06c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMO_PATH = \"./mean_data.csv\"\n",
    "MEL_ARR_PATH = \"./split_mel_array\"\n",
    "SAVE_PATH = \"./save_models\"\n",
    "    \n",
    "mel_arr_data = MelData(MEL_ARR_PATH)\n",
    "#emo_data = EmotionalData(EMO_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_arr_data_loader = DataLoader(\n",
    "        dataset=mel_arr_data, batch_size=batch_size)\n",
    "\n",
    "#emo_data_loader = DataLoader(\n",
    "#        dataset=emo_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled(x):\n",
    "    return (x + 80.0) / (3.8147e-06 + 80)\n",
    "def unscaled(x):\n",
    "    return x * (3.8147e-06 + 80) - 80.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract idices\n",
    "# torch.Size([32, 10, 128]) torch.Size([32, 20, 256])\n",
    "def extract_indice(mel_data, model):\n",
    "    with torch.no_grad():\n",
    "        for _, mel in mel_data:\n",
    "            x = scaled(mel)\n",
    "            x = x.unsqueeze(1).to(device)\n",
    "            _, _, _, ids = model.encode(x)\n",
    "            try:\n",
    "                ids_t = torch.cat([ids_t, ids[0]], dim=0)\n",
    "                ids_m = torch.cat([ids_m, ids[1]], dim=0)\n",
    "                ids_b = torch.cat([ids_b, ids[2]], dim=0)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                ids_t, ids_m, ids_b = ids[0].clone().detach(), ids[1].clone().detach(), ids[2].clone().detach()\n",
    "    return ids_t, ids_m, ids_b\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = 128 #128\n",
    "num_residual_hiddens = 32\n",
    "num_residual_layers = 4\n",
    "embedding_dim = 64 #64 : 코드북에서 한 ebedding의 크기\n",
    "num_embeddings = 256 #512 : embbeding vector 개수 -> indices의 최대 크기\n",
    "commitment_cost = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vq_vae_2_half_tmb\n",
    "importlib.reload(vq_vae_2_half_tmb)\n",
    "from vq_vae_2_half_tmb import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(num_hiddens=num_hiddens, \n",
    "                  num_residual_layers=num_residual_layers,\n",
    "                  num_residual_hiddens=num_residual_hiddens,\n",
    "                  num_embeddings=num_embeddings,\n",
    "                  embedding_dim=embedding_dim, \n",
    "                  commitment_cost=commitment_cost).to(device)\n",
    "\n",
    "score = 0.008331568911671638\n",
    "MODEL_PATH = f'{SAVE_PATH}/vqvae2_tmb-{score:.5f}_dict.pt'\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local variable 'ids_t' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "ids_t, ids_m, ids_b = extract_indice(mel_arr_data_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mel_arr_data_loader, mel_arr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18232, 10, 16]) torch.Size([18232, 20, 32]) torch.Size([18232, 40, 64])\n"
     ]
    }
   ],
   "source": [
    "print(ids_t.size(), ids_m.size(), ids_b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(hier, epoch, loader, model, optimizer, scheduler, device):\n",
    "    \n",
    "    loader = tqdm(loader)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for i, data in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        top, middle, bottom = data\n",
    "\n",
    "        top = top.to(device)\n",
    "        # print(top.shape, bottom.shape)\n",
    "\n",
    "        if hier == 'top':\n",
    "            target = top\n",
    "            out, _ = model(top)\n",
    "            \n",
    "        elif hier == 'middle':\n",
    "            target = middle.to(device) # bottom\n",
    "            out, _ = model(target, condition=top)\n",
    "            \n",
    "        elif hier == 'bottom':\n",
    "            target = bottom.to(device)\n",
    "            out, _ = model(target, condition=middle)\n",
    "\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = out.max(1)\n",
    "        correct = (pred == target).float()\n",
    "        accuracy = correct.sum() / target.numel()\n",
    "\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        wandb.log({\n",
    "                \"Loss\": loss,\n",
    "                \"Accuracy\": accuracy\n",
    "        })\n",
    "        \n",
    "        loader.set_description(\n",
    "            (\n",
    "                f'epoch: {epoch + 1}\\t loss: {loss.item():.5f}\\t '\n",
    "                f'acc: {accuracy:.5f}\\t lr: {lr:.5f}'\n",
    "            )\n",
    "        )\n",
    "\n",
    "class PixelTransform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, input):\n",
    "        ar = np.array(input)\n",
    "\n",
    "        return torch.from_numpy(ar).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 800\n",
    "channel = 512\n",
    "n_res_block = 4\n",
    "n_res_channel = 256\n",
    "n_out_res_block = 0\n",
    "n_cond_res_block = 3\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDsData(Dataset):\n",
    "    def __init__(self, ids_t, ids_m, ids_b):\n",
    "        self.ids_t = ids_t\n",
    "        self.ids_m = ids_m\n",
    "        self.ids_b = ids_b\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids_t)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.ids_t[idx], self.ids_m[idx], self.ids_b[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_data = IDsData(ids_t, ids_m, ids_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, pixel_snail\n",
    "importlib.reload(pixel_snail)\n",
    "from pixel_snail import PixelSNAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bottom = PixelSNAIL(\n",
    "    [40, 64], # [20, 256]\n",
    "    256,\n",
    "    channel,\n",
    "    5,\n",
    "    4,\n",
    "    n_res_block,\n",
    "    n_res_channel,\n",
    "    attention=False,\n",
    "    dropout=dropout,\n",
    "    n_cond_res_block=n_cond_res_block,\n",
    "    cond_res_channel=n_res_channel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bottom = model_bottom.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c177fbcf0d5748999b88d2fd738c411f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf9825e3d4c4351a260632e2c87f973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/569 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07a7bb7c6574e2c82a0a73d56e2668d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/569 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265d7901a0644d658d6ecf5839d1754f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/569 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bcbc097ae04e608fe90608aa3aae01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/569 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287cd1bce3184177a4adcad887dcfa72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/569 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ebb127808d4445a2ff73321b4d98ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/569 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95625a7d2274baab97a2017bf32e962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/569 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2609bb98d8274989b57e4bab2bb607b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/569 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c14e9b8f43d48a393c903631d07b3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/569 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "batch = 8\n",
    "# model_bottom.load_state_dict(torch.load(f'{SAVE_PATH}/pixelsnail_ckp/pixelsnail_bot_tmb.pt'))\n",
    "ids_loader = DataLoader(\n",
    "        ids_data, batch_size=batch, shuffle=True, drop_last=True\n",
    "    )\n",
    "optimizer_bottom = optim.Adam(model_bottom.parameters(), lr=lr)\n",
    "scheduler_bottom = CycleScheduler(optimizer_bottom, lr, n_iter=len(ids_loader) * epoch, momentum=None)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for i in tqdm(range(epoch)):\n",
    "    train('bottom', i, ids_loader, model_bottom.to(device), optimizer_bottom, None, device)\n",
    "    torch.save(model_bottom.state_dict(), f'{SAVE_PATH}/pixelsnail_ckp/pixelsnail_bot_tmb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mel_arr_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13452/3817404663.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model_bottom.load_state_dict(torch.load(f'{SAVE_PATH}/pixelsnail_ckp/pixelsnail_bot_tmb.pt'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m mel_arr_data_loader = DataLoader(\n\u001b[0;32m----> 5\u001b[0;31m         dataset=mel_arr_data, batch_size=batch_size)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0moptimizer_bottom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_bottom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscheduler_bottom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCycleScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_bottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_arr_data_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mel_arr_data' is not defined"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 8\n",
    "#model_bottom.load_state_dict(torch.load(f'{SAVE_PATH}/pixelsnail_ckp/pixelsnail_bot_tmb.pt'))\n",
    "mel_arr_data_loader = DataLoader(\n",
    "        dataset=mel_arr_data, batch_size=batch_size)\n",
    "optimizer_bottom = optim.Adam(model_bottom.parameters(), lr=lr)\n",
    "scheduler_bottom = CycleScheduler(optimizer_bottom, lr, n_iter=len(mel_arr_data_loader) * epoch, momentum=None)\n",
    "\n",
    "for i in tqdm(range(epoch)):\n",
    "    train('bottom', i, mel_arr_data_loader, model, model_bottom.to(device), optimizer_bottom, None, device, batch)\n",
    "    torch.save(model_bottom.state_dict(), f'{SAVE_PATH}/pixelsnail_ckp/pixelsnail_bot_tmb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('audio': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9625287269220251dd2f53164d2a112ab09cf8e86b35d6b73b22f9f410170108"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
