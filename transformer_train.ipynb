{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Xi Chen\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "# Borrowed from https://github.com/neocxi/pixelsnail-public and ported it to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from vq_vae_2_half_tmb import Model\n",
    "from transformer import VQVAETransformer\n",
    "from lr_scheduler import WarmupLinearLRSchedule\n",
    "from torchvision import utils as vutils\n",
    "#from utils import load_data, plot_images\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqja1998\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gibeom/audio/emotional_annotations/wandb/run-20221109_154624-3e9yy2q3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/qja1998/audio-emotional_annotations/runs/3e9yy2q3\" target=\"_blank\">atomic-gorge-64</a></strong> to <a href=\"https://wandb.ai/qja1998/audio-emotional_annotations\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()\n",
    "wandb.run.name = 'transformer_mid'\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelData(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = []\n",
    "        genre = ['classical', 'rock', 'electronic', 'pop']\n",
    "        \n",
    "        for g in genre:\n",
    "            for i in range(1, 101):\n",
    "                for j in range(5):\n",
    "                    tmp_path = f'{file_path}/{g}/{i}-{j}.csv'\n",
    "                    try:\n",
    "                        self.data.append((pd.read_csv(tmp_path), g, i, j))\n",
    "                    except FileNotFoundError:\n",
    "                        print(f\"{g}-{i}-{j} file is deleted\")\n",
    "                        continue\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mel, g, i, j = self.data[idx]\n",
    "        mel = torch.from_numpy(pd.get_dummies(mel).values)\n",
    "        mel = mel.type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        return (g, i, j), mel\n",
    "\n",
    "class EmotionalData(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tmp_data = self.data.iloc[idx]\n",
    "        genre, idx = tmp_data[0].split('_')\n",
    "        emo = tmp_data[1:]\n",
    "        return idx, genre, torch.FloatTensor(emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical-16-0 file is deleted\n",
      "classical-16-1 file is deleted\n",
      "classical-16-2 file is deleted\n",
      "classical-16-3 file is deleted\n",
      "classical-16-4 file is deleted\n",
      "classical-40-0 file is deleted\n",
      "classical-40-1 file is deleted\n",
      "classical-40-2 file is deleted\n",
      "classical-40-3 file is deleted\n",
      "classical-40-4 file is deleted\n",
      "classical-57-0 file is deleted\n",
      "classical-57-1 file is deleted\n",
      "classical-57-2 file is deleted\n",
      "classical-57-3 file is deleted\n",
      "classical-57-4 file is deleted\n",
      "classical-66-0 file is deleted\n",
      "classical-66-1 file is deleted\n",
      "classical-66-2 file is deleted\n",
      "classical-66-3 file is deleted\n",
      "classical-66-4 file is deleted\n",
      "classical-73-0 file is deleted\n",
      "classical-73-1 file is deleted\n",
      "classical-73-2 file is deleted\n",
      "classical-73-3 file is deleted\n",
      "classical-73-4 file is deleted\n"
     ]
    }
   ],
   "source": [
    "EMO_PATH = \"./mean_data.csv\"\n",
    "MEL_ARR_PATH = \"./split_mel_array\"\n",
    "SAVE_PATH = \"./save_models\"\n",
    "    \n",
    "mel_arr_data = MelData(MEL_ARR_PATH)\n",
    "#emo_data = EmotionalData(EMO_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_arr_data_loader = DataLoader(\n",
    "        dataset=mel_arr_data, batch_size=batch_size)\n",
    "\n",
    "#emo_data_loader = DataLoader(\n",
    "#        dataset=emo_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled(x):\n",
    "    return (x + 80.0) / (3.8147e-06 + 80)\n",
    "def unscaled(x):\n",
    "    return x * (3.8147e-06 + 80) - 80.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract idices\n",
    "# torch.Size([32, 10, 128]) torch.Size([32, 20, 256])\n",
    "def extract_indice(mel_data, model):\n",
    "    with torch.no_grad():\n",
    "        for _, mel in mel_data:\n",
    "            x = scaled(mel)\n",
    "            x = x[:, :, :-2].unsqueeze(1).to(device)\n",
    "            _, _, _, ids = model.encode(x)\n",
    "            try:\n",
    "                ids_t = torch.cat([ids_t, ids[0]], dim=0)\n",
    "                ids_m = torch.cat([ids_m, ids[1]], dim=0)\n",
    "                ids_b = torch.cat([ids_b, ids[2]], dim=0)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                ids_t, ids_m, ids_b = ids[0].clone().detach(), ids[1].clone().detach(), ids[2].clone().detach()\n",
    "    return ids_t, ids_m, ids_b\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = 128 #128\n",
    "num_residual_hiddens = 32\n",
    "num_residual_layers = 4\n",
    "embedding_dim = 16 #64\n",
    "num_embeddings = 128 #512\n",
    "commitment_cost = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vqvae = Model(num_hiddens=num_hiddens, \n",
    "                  num_residual_layers=num_residual_layers,\n",
    "                  num_residual_hiddens=num_residual_hiddens,\n",
    "                  num_embeddings=num_embeddings,\n",
    "                  embedding_dim=embedding_dim, \n",
    "                  commitment_cost=commitment_cost).to(device)\n",
    "\n",
    "score = 0.009567060507833958\n",
    "MODEL_PATH = f'{SAVE_PATH}/vqvae2_tmb_split10-{score:.5f}_dict.pt'\n",
    "vqvae.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local variable 'ids_t' referenced before assignment\n",
      "torch.Size([1975, 10, 16]) torch.Size([1975, 20, 32]) torch.Size([1975, 40, 64])\n"
     ]
    }
   ],
   "source": [
    "ids_t, ids_m, ids_b = extract_indice(mel_arr_data_loader, vqvae)\n",
    "print(ids_t.shape, ids_m.shape, ids_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 48, 40, 64])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    quant_t = vqvae.vq_top.embed_code(ids_t[0]).unsqueeze(0)\n",
    "    quant_t = quant_t.permute(0, 3, 1, 2).contiguous()\n",
    "    quant_m = vqvae.vq_mid.embed_code(ids_m[0]).unsqueeze(0)\n",
    "    quant_m = quant_m.permute(0, 3, 1, 2).contiguous()\n",
    "    quant_b = vqvae.vq_bot.embed_code(ids_b[0]).unsqueeze(0)\n",
    "    quant_b = quant_b.permute(0, 3, 1, 2).contiguous()\n",
    "    upsample_t = vqvae.upsample_tx2(quant_t)\n",
    "    upsample_m = vqvae.upsample_t(quant_m)\n",
    "    quantized = torch.cat([upsample_t, upsample_m, quant_b], 1)\n",
    "print(quantized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, transformer\n",
    "importlib.reload(transformer)\n",
    "from transformer import VQVAETransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTransformer:\n",
    "    def __init__(self, args, data, lev):\n",
    "        self.model = VQVAETransformer(args).to(device=args.device)\n",
    "        self.optim = self.configure_optimizers()\n",
    "        self.lr_schedule = WarmupLinearLRSchedule(\n",
    "            optimizer=self.optim,\n",
    "            init_lr=1e-6,\n",
    "            peak_lr=args.learning_rate,\n",
    "            end_lr=0.,\n",
    "            warmup_epochs=10,\n",
    "            epochs=args.epochs,\n",
    "            current_step=args.start_from_epoch\n",
    "        )\n",
    "        #self.lr_schedule = AdafactorSchedule(self.optim, initial_lr=1e-2)\n",
    "\n",
    "        if args.start_from_epoch > 1:\n",
    "            self.model.load_checkpoint(args.start_from_epoch)\n",
    "            print(f\"Loaded Transformer from epoch {args.start_from_epoch}.\")\n",
    "        \n",
    "        wandb.watch(self.model)\n",
    "        self.lev = lev\n",
    "        self.train(args, data)\n",
    "\n",
    "    def train(self, args, data):\n",
    "        train_dataset = data\n",
    "        len_train_dataset = len(train_dataset)\n",
    "        step = args.start_from_epoch * len_train_dataset\n",
    "        for epoch in range(args.start_from_epoch+1, args.epochs+1):\n",
    "            print(f\"Epoch {epoch}:\")\n",
    "            with tqdm(range(len(train_dataset))) as pbar:\n",
    "                for i, (ids_t, ids_m, ids_b) in zip(pbar, train_dataset):\n",
    "                    if self.lev == 'top':\n",
    "                        imgs = ids_t\n",
    "                    elif self.lev == 'mid':\n",
    "                        imgs = ids_m\n",
    "                    elif self.lev == 'bot':\n",
    "                        imgs = ids_b\n",
    "                    imgs = imgs.to(device=args.device)\n",
    "                    logits, target = self.model(imgs)\n",
    "                    loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), target.reshape(-1)).requires_grad_(True)\n",
    "                    loss.backward()\n",
    "                    if step % args.accum_grad == 0:\n",
    "                        self.optim.step()\n",
    "                        self.optim.zero_grad()\n",
    "                    step += 1\n",
    "                    pbar.set_postfix(Transformer_Loss=np.round(loss.cpu().detach().numpy().item(), 4))\n",
    "                    pbar.update(0)\n",
    "                    \n",
    "                    pbar.set_description(\n",
    "                    (\n",
    "                        f\" lr {self.optim.param_groups[0]['lr']:.6f}\\t\"\n",
    "                    )\n",
    "                    )\n",
    "                    wandb.log({\n",
    "                        \"Loss\": loss,\n",
    "                        \"Learning rate\": self.optim.param_groups[0]['lr']\n",
    "                    })\n",
    "                self.lr_schedule.step()\n",
    "            try:\n",
    "                log, sampled_imgs = self.model.log_images(imgs[0:1])\n",
    "                vutils.save_image(sampled_imgs.add(1).mul(0.5), os.path.join(\"results\", f\"{epoch}.jpg\"), nrow=4)\n",
    "                #plot_images(log)\n",
    "            except:\n",
    "                pass\n",
    "            #if epoch % args.ckpt_interval == 0:\n",
    "            #    torch.save(self.model.state_dict(), os.path.join(\"checkpoints\", f\"transformer_epoch_{epoch}.pt\"))\n",
    "            torch.save(self.model.state_dict(), os.path.join(f\"checkpoints\", \"transformer_current_{self.lev}.pt\"))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # decay, no_decay = set(), set()\n",
    "        # whitelist_weight_modules = (nn.Linear,)\n",
    "        # blacklist_weight_modules = (nn.LayerNorm, nn.Embedding)\n",
    "        # for mn, m in self.model.transformer.named_modules():\n",
    "        #     for pn, p in m.named_parameters():\n",
    "        #         fpn = '%s.%s' % (mn, pn) if mn else pn  # full param name\n",
    "        #\n",
    "        #         if pn.endswith('bias'):\n",
    "        #             no_decay.add(fpn)\n",
    "        #\n",
    "        #         elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
    "        #             decay.add(fpn)\n",
    "        #\n",
    "        #         elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
    "        #             no_decay.add(fpn)\n",
    "        #\n",
    "        # # no_decay.add('pos_emb')\n",
    "        #\n",
    "        # param_dict = {pn: p for pn, p in self.model.transformer.named_parameters()}\n",
    "        #\n",
    "        # optim_groups = [\n",
    "        #     {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": 4.5e-2},\n",
    "        #     {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n",
    "        # ]\n",
    "        optimizer = torch.optim.Adam(self.model.transformer.parameters(), lr=1e-6, betas=(0.9, 0.96), weight_decay=4.5e-2)\n",
    "        #optimizer = Adafactor(self.model.parameters(), lr=0.0, scale_parameter=True, relative_step=False)\n",
    "        #optimizer = Adafactor(self.model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"VQGAN\")\n",
    "parser.add_argument('--run-name', type=str, default=None)\n",
    "parser.add_argument('--latent-dim', type=int, default=32, help='Latent dimension n_z.')\n",
    "parser.add_argument('--image-size', type=int, default=256, help='Image height and width.)')\n",
    "parser.add_argument('--num-codebook-vectors', type=int, default=8192, help='Number of codebook vectors.')\n",
    "parser.add_argument('--beta', type=float, default=0.25, help='Commitment loss scalar.')\n",
    "parser.add_argument('--image-channels', type=int, default=3, help='Number of channels of images.')\n",
    "parser.add_argument('--dataset-path', type=str, default='./data', help='Path to data.')\n",
    "parser.add_argument('--checkpoint-path', type=str, default='./checkpoints/last_ckpt.pt', help='Path to checkpoint.')\n",
    "parser.add_argument('--device', type=str, default=\"cuda\", help='Which device the training is on.')\n",
    "parser.add_argument('--batch-size', type=int, default=10, help='Batch size for training.')\n",
    "parser.add_argument('--accum-grad', type=int, default=10, help='Number for gradient accumulation.')\n",
    "parser.add_argument('--epochs', type=int, default=300, help='Number of epochs to train.')\n",
    "parser.add_argument('--start-from-epoch', type=int, default=1, help='Number of epochs to train.')\n",
    "parser.add_argument('--ckpt-interval', type=int, default=100, help='Number of epochs to train.')\n",
    "parser.add_argument('--learning-rate', type=float, default=1e-4, help='Learning rate.')\n",
    "\n",
    "parser.add_argument('--sos-token', type=int, default=1025, help='Start of Sentence token.')\n",
    "\n",
    "parser.add_argument('--n-layers', type=int, default=24, help='Number of layers of transformer.')\n",
    "parser.add_argument('--dim', type=int, default=768, help='Dimension of transformer.')\n",
    "parser.add_argument('--hidden-dim', type=int, default=3072, help='Dimension of transformer.')\n",
    "parser.add_argument('--num-image-tokens', type=int, default=256, help='Number of image tokens.')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "args.run_name = \"<name>\"\n",
    "args.dataset_path = r\"C:\\Users\\dome\\datasets\\landscape\"\n",
    "args.checkpoint_path = r\".\\checkpoints\"\n",
    "args.n_layers = 24\n",
    "args.dim = 512\n",
    "args.hidden_dim = 3072\n",
    "args.batch_size = 4\n",
    "args.accum_grad = 25\n",
    "args.epochs = 200\n",
    "\n",
    "args.start_from_epoch = 0\n",
    "\n",
    "args.num_codebook_vectors = 511\n",
    "args.num_image_tokens = 20 * 64\n",
    "\n",
    "wandb.config.update(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDsData(Dataset):\n",
    "    def __init__(self, ids_t, ids_m, ids_b):\n",
    "        self.ids_t = ids_t\n",
    "        self.ids_m = ids_m\n",
    "        self.ids_b = ids_b\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids_t)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.ids_t[idx], self.ids_m[idx], self.ids_b[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(ids_t)\n",
    "ids_data = IDsData(ids_t.view(length, -1), ids_m.view(length, -1), ids_b.view(length, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1\n",
    "ids_loader = DataLoader(\n",
    "        ids_data, batch_size=batch, shuffle=True, drop_last=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Module Embedding.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module NonDynamicallyQuantizableLinear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Initializing Module Linear.\n",
      "Transformer parameters: 102688001\n",
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000001\t: 100%|██████████| 1975/1975 [08:31<00:00,  3.86it/s, Transformer_Loss=5.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000001\t: 100%|██████████| 1975/1975 [08:38<00:00,  3.81it/s, Transformer_Loss=4.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000011\t: 100%|██████████| 1975/1975 [08:39<00:00,  3.80it/s, Transformer_Loss=3.85] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000021\t: 100%|██████████| 1975/1975 [08:39<00:00,  3.80it/s, Transformer_Loss=4.04] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000031\t: 100%|██████████| 1975/1975 [08:39<00:00,  3.80it/s, Transformer_Loss=2.01]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000041\t: 100%|██████████| 1975/1975 [08:39<00:00,  3.80it/s, Transformer_Loss=2.5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000050\t: 100%|██████████| 1975/1975 [08:40<00:00,  3.80it/s, Transformer_Loss=0.311] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000060\t: 100%|██████████| 1975/1975 [08:39<00:00,  3.80it/s, Transformer_Loss=0.791] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000070\t: 100%|██████████| 1975/1975 [08:40<00:00,  3.79it/s, Transformer_Loss=0.0815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000080\t: 100%|██████████| 1975/1975 [08:39<00:00,  3.80it/s, Transformer_Loss=0.841] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000090\t: 100%|██████████| 1975/1975 [08:39<00:00,  3.80it/s, Transformer_Loss=0.719] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " lr 0.000100\t:  18%|█▊        | 352/1975 [01:33<07:09,  3.78it/s, Transformer_Loss=0.933] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18477/3201004767.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_18477/3081898848.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, data, lev)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18477/3081898848.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, args, data)\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccum_grad\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/audio/lib/python3.10/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/audio/lib/python3.10/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_transformer = TrainTransformer(args, ids_loader, lev='mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_transformer.model.state_dict(), os.path.join(\"checkpoints\", \"transformer_current_mid.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('audio')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9625287269220251dd2f53164d2a112ab09cf8e86b35d6b73b22f9f410170108"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
