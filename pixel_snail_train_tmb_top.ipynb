{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Xi Chen\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "# Borrowed from https://github.com/neocxi/pixelsnail-public and ported it to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import importlib \n",
    "from math import sqrt\n",
    "from functools import partial, lru_cache\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from vq_vae_2 import Model\n",
    "from pixel_snail import PixelSNAIL\n",
    "from scheduler import CycleScheduler\n",
    "\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqja1998\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gibeom/audio/emotional_annotations/wandb/run-20230207_063139-2vjdjjwr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/qja1998/audio-emotional_annotations/runs/2vjdjjwr\" target=\"_blank\">fallen-morning-184</a></strong> to <a href=\"https://wandb.ai/qja1998/audio-emotional_annotations\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()\n",
    "wandb.run.name = 'PixelSNAIL top'\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_split = 100\n",
    "class MelData(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = []\n",
    "        genre = ['classical', 'rock', 'electronic', 'pop', 'deam']\n",
    "        print(\"Load data...\")\n",
    "        for g in genre:\n",
    "            print(f'{g}:')\n",
    "            for i in tqdm(range(1, 2059)):\n",
    "                for j in range(num_split):\n",
    "                    tmp_path = f'{file_path}/{g}/{i}-{j}.csv'\n",
    "                    try:\n",
    "                        mel = pd.read_csv(tmp_path).iloc[:, :512]\n",
    "                        if mel.shape == (80, 512):\n",
    "                            self.data.append((mel, g, i, j))\n",
    "                    except FileNotFoundError:\n",
    "                        continue\n",
    "            print()\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mel, g, i, j = self.data[idx]\n",
    "        mel = torch.from_numpy(pd.get_dummies(mel).values)\n",
    "        mel = mel.type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        return (g, i, j), mel\n",
    "\n",
    "class EmotionalData(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tmp_data = self.data.iloc[idx]\n",
    "        genre, idx = tmp_data[0].split('_')\n",
    "        emo = tmp_data[1:]\n",
    "        return idx, genre, torch.FloatTensor(emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "classical:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6430fa165f44bebb42d1e3449212ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rock:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bc9e4ec74b49db9561bacb545144f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "electronic:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5226e00357416fb957d5cc0333b73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pop:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498ee73156a24b97a637adf1bbe42cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "deam:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d06c769dc04623baa534ce9d99c463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2058 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EMO_PATH = \"./mean_data.csv\"\n",
    "MEL_ARR_PATH = \"./split_mel_array\"\n",
    "SAVE_PATH = \"./save_models\"\n",
    "    \n",
    "mel_arr_data = MelData(MEL_ARR_PATH)\n",
    "#emo_data = EmotionalData(EMO_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_arr_data_loader = DataLoader(\n",
    "        dataset=mel_arr_data, batch_size=batch_size)\n",
    "\n",
    "#emo_data_loader = DataLoader(\n",
    "#        dataset=emo_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled(x):\n",
    "    return (x + 80.0) / (3.8147e-06 + 80)\n",
    "def unscaled(x):\n",
    "    return x * (3.8147e-06 + 80) - 80.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract idices\n",
    "# torch.Size([32, 10, 128]) torch.Size([32, 20, 256])\n",
    "def extract_indice(mel_data, model):\n",
    "    with torch.no_grad():\n",
    "        for _, mel in mel_data:\n",
    "            x = scaled(mel)\n",
    "            x = x.unsqueeze(1).to(device)\n",
    "            _, _, _, ids = model.encode(x)\n",
    "            try:\n",
    "                ids_t = torch.cat([ids_t, ids[0]], dim=0)\n",
    "                ids_m = torch.cat([ids_m, ids[1]], dim=0)\n",
    "                ids_b = torch.cat([ids_b, ids[2]], dim=0)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                ids_t, ids_m, ids_b = ids[0].clone().detach(), ids[1].clone().detach(), ids[2].clone().detach()\n",
    "    return ids_t, ids_m, ids_b\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = 128 #128\n",
    "num_residual_hiddens = 32\n",
    "num_residual_layers = 4\n",
    "embedding_dim = 64 #64 : 코드북에서 한 ebedding의 크기\n",
    "num_embeddings = 256 #512 : embbeding vector 개수 -> indices의 최대 크기\n",
    "commitment_cost = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vq_vae_2_half_tmb\n",
    "importlib.reload(vq_vae_2_half_tmb)\n",
    "from vq_vae_2_half_tmb import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(num_hiddens=num_hiddens, \n",
    "                  num_residual_layers=num_residual_layers,\n",
    "                  num_residual_hiddens=num_residual_hiddens,\n",
    "                  num_embeddings=num_embeddings,\n",
    "                  embedding_dim=embedding_dim, \n",
    "                  commitment_cost=commitment_cost).to(device)\n",
    "\n",
    "score = 0.008331568911671638\n",
    "MODEL_PATH = f'{SAVE_PATH}/vqvae2_tmb-{score:.5f}_dict.pt'\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local variable 'ids_t' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "ids_t, ids_m, ids_b = extract_indice(mel_arr_data_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mel_arr_data_loader, mel_arr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18232, 10, 16]) torch.Size([18232, 20, 32]) torch.Size([18232, 40, 64])\n"
     ]
    }
   ],
   "source": [
    "print(ids_t.size(), ids_m.size(), ids_b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(hier, epoch, loader, model, optimizer, scheduler, device, batch_size):\n",
    "    \n",
    "    loader = tqdm(loader)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for i, data in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        top, middle, bottom = data\n",
    "\n",
    "        top = top.to(device)\n",
    "        # print(top.shape, bottom.shape)\n",
    "\n",
    "        if hier == 'top':\n",
    "            target = top\n",
    "            out, _ = model(top)\n",
    "            \n",
    "        elif hier == 'middle':\n",
    "            target = middle.to(device) # bottom\n",
    "            out, _ = model(target, condition=top)\n",
    "            \n",
    "        elif hier == 'bottom':\n",
    "            target = bottom.to(device)\n",
    "            out, _ = model(target, condition=middle)\n",
    "\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = out.max(1)\n",
    "        correct = (pred == target).float()\n",
    "        accuracy = correct.sum() / target.numel()\n",
    "\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        wandb.log({\n",
    "                \"Loss\": loss,\n",
    "                \"Accuracy\": accuracy\n",
    "        })\n",
    "        \n",
    "        loader.set_description(\n",
    "            (\n",
    "                f'epoch: {epoch + 1}\\t loss: {loss.item():.5f}\\t '\n",
    "                f'acc: {accuracy:.5f}\\t lr: {lr:.5f}'\n",
    "            )\n",
    "        )\n",
    "\n",
    "class PixelTransform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, input):\n",
    "        ar = np.array(input)\n",
    "\n",
    "        return torch.from_numpy(ar).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 4\n",
    "epoch = 201\n",
    "lr = 1e-5 # 1e-4 bottom\n",
    "channel = 512\n",
    "n_res_block = 4\n",
    "n_res_channel = 128\n",
    "n_out_res_block = 0\n",
    "n_cond_res_block = 3\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDsData(Dataset):\n",
    "    def __init__(self, ids_t, ids_m, ids_b):\n",
    "        self.ids_t = ids_t\n",
    "        self.ids_m = ids_m\n",
    "        self.ids_b = ids_b\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids_t)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.ids_t[idx], self.ids_m[idx], self.ids_b[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_data = IDsData(ids_t, ids_m, ids_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_loader = DataLoader(\n",
    "        ids_data, batch_size=batch, shuffle=True, drop_last=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, pixel_snail\n",
    "importlib.reload(pixel_snail)\n",
    "from pixel_snail import PixelSNAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 4\n",
    "epoch = 201\n",
    "lr = 3e-4 # 1e-4 bottom\n",
    "channel = 256\n",
    "n_res_block = 4\n",
    "n_res_channel = 256\n",
    "n_out_res_block = 0\n",
    "n_cond_res_block = 3\n",
    "dropout = 0.1\n",
    "\n",
    "model_top = PixelSNAIL(\n",
    "    [10, 16], # [32, 40],\n",
    "    1024,\n",
    "    channel,\n",
    "    5,\n",
    "    4,\n",
    "    n_res_block,\n",
    "    n_res_channel,\n",
    "    dropout=dropout,\n",
    "    n_out_res_block=n_out_res_block,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "ids_loader = DataLoader(\n",
    "        ids_data, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "model_top = model_top.to(device)\n",
    "optimizer_top = optim.Adam(model_top.parameters(), lr=lr)\n",
    "\n",
    "scheduler_top = CycleScheduler(optimizer_top, lr, n_iter=len(ids_loader) * epoch, momentum=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549edf34e6594ee3893ebdf8a3b90836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97788e29bf67442987d5e891620d3a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3c7eda726e4eeab90e0f8457b302cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e56144380e8439baf6e2bd7593a1ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bdd4df9d784c7299c3608ca8c23c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b46400262f40b3b4afde9e89b4a5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076dde2525eb48628c731201a9b56296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a0e635d5444a00a1edaf5f0b37b767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf661cfebee473dbc0668fe5a3a79dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8574e0e7d54a1fac0d8bbb98955e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = 10\n",
    "for i in range(epoch):\n",
    "    loss = train('top', i, ids_loader, model_top, optimizer_top, None, device, batch_size)\n",
    "    torch.save(model_top.state_dict(), f'{SAVE_PATH}/pixelsnail_ckp/pixelsnail_top_tmb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_top.state_dict(), f'{SAVE_PATH}/pixelsnail_ckp/pixelsnail_top_tmb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 8\n",
    "mel_arr_data_loader = DataLoader(\n",
    "        dataset=mel_arr_data, batch_size=batch_size)\n",
    "\n",
    "model_top = model_top.to(device)\n",
    "optimizer_top = optim.Adam(model_top.parameters(), lr=lr)\n",
    "\n",
    "scheduler_top = CycleScheduler(optimizer_top, lr, n_iter=len(mel_arr_data_loader) * epoch, momentum=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7092f2bc42e045c89a449bfd1ba0dcc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a33ac2d782e457d93bac83eb0e0d623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f307f6bddc5f49668d60138a1aee9234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200a5eb954b8400fbfd24e02f7995d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c335e368e44f078d98a95b62748bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd2a756b50e4365a709a7f36ddb8ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331d7f46acab452489d820cd79084f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ef51aba7744fedb4ee0e9237ac52b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6bcd6a85ab4d28a8eabf5b12673886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a3bfc704f648a5b051c2c11d425949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = 10\n",
    "for i in range(epoch):\n",
    "    loss = train('top', i, mel_arr_data_loader, model, model_top, optimizer_top, None, device, batch_size)\n",
    "    torch.save(model_top.state_dict(), f'{SAVE_PATH}/pixelsnail_ckp/pixelsnail_top_tmb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('audio': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9625287269220251dd2f53164d2a112ab09cf8e86b35d6b73b22f9f410170108"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
